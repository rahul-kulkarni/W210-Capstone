This repo contains all the experiments and code for our paper (in the docs directory)

# NLP Generalization for QA Tasks 

Rahul Kulkarni 		      Kevin Hanna  			Justin Stanely

W210 Summer 2020, MIDS, UC Berkeley School of Information
04 August 2020

{rahul.kulkarni, kevinhanna,  justinstanely}@berkeley.edu


Abstract 

We are motivated to understand the challenges of generalization of natural language models on unseen data specifically for extractive question and answering tasks.  We analyze existing studies for understanding the generalization gap, conduct experiments to further characterize the generalization gap and apply techniques used for improving model robustness on language models.

Keywords: NLP, generalization, model robustness 
