{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import collections\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from hyphen import Hyphenator\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import stanfordnlp\n",
    "from stanfordnlp.server import CoreNLPClient\n",
    "\n",
    "# Uncomment if needed to fix this error:\n",
    "# OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_PATH = './predictions'\n",
    "TEST_SETS_PATH = './test_sets'\n",
    "\n",
    "#SET_NAMES = ['Amazon', 'Reddit', 'New-Wiki', 'NYT', 'dev-v1.1']\n",
    "SET_NAMES = ['Amazon', 'Reddit', 'New-Wiki', 'NYT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        return [r for r in csv_reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = pd.read_csv('answers.csv')\n",
    "df_distinct_answers = pd.read_csv('distinct_answers.csv')\n",
    "df_distinct_context = pd.read_csv('distinct_context.csv')\n",
    "df_merged_answers = pd.read_csv('merged_answers.com')\n",
    "df_merged_answers_and_context = pd.read_csv('merged_answers_and_context.csv')\n",
    "df_pred_answers_context = pd.read_csv('pred_answers_context.csv')\n",
    "\n",
    "df_pred = pd.DataFrameload_data(PREDICTION_PATH + '/all_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred.astype({'f1': 'float'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['f1'].hist(by=df_pred['test_set'],density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4, figsize= (20,5))\n",
    "fig.suptitle('Test Set F1 Histogram by %')\n",
    "for i, test_set in enumerate(df_pred['test_set'].unique()):\n",
    "    data = df_pred[df_pred['test_set'] == test_set]['f1']\n",
    "    data.hist(ax=axes.flat[i], \n",
    "            bins=20, \n",
    "            weights=np.ones(len(data)) / len(data) \n",
    "           )\n",
    "    axes.flat[i].set_title(test_set)\n",
    "for ax in axes:\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4, figsize= (20,5))\n",
    "fig.suptitle('Test Set F1 Histogram by Count')\n",
    "for i, test_set in enumerate(df_pred['test_set'].unique()):\n",
    "    data = df_pred[df_pred['test_set'] == test_set]['f1']\n",
    "    data.hist(ax=axes.flat[i], \n",
    "            bins=20\n",
    "           )\n",
    "    axes.flat[i].set_title(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[df_pred['test_set'] == 'dev-v1.1']['f1'].hist(bins=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1)\n",
    "axes.hist(df_pred[df_pred['test_set'] == 'Amazon']['f1'], \n",
    "          weights=np.ones(len(df_pred[df_pred['test_set'] == 'Amazon']['f1'])) / len(df_pred[df_pred['test_set'] == 'Amazon']['f1']) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct_context.sort_values('flesch-kincaid_grade_level', ascending=False).iloc[2]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct_context.iloc[1519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct_context.sort_values(\n",
    "    'flesch-kincaid_grade_level', \n",
    "    ascending=False).iloc[2:3][[\n",
    "                                'sentence_count', \n",
    "                                'word_count', \n",
    "                                'flesch-kincaid_grade_level', \n",
    "                                'coleman-liau', \n",
    "                                'gunning-fog', \n",
    "                                'automated-readability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp(df_distinct_context.sort_values('flesch-kincaid_grade_level', ascending=False).iloc[2]['context']).sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct_context.sort_values('flesch-kincaid_grade_level', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct_context.sort_values('flesch-kincaid_grade_level', ascending=False).iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'University of the Philippines College of Medicine'.split()\n",
    "for w in x:\n",
    "    print(w, Hyphenator('en_US').syllables(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_answers[df_merged_answers['question_id'] == '5dd469facc027a086d65bf1a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_answers[df_merged_answers['is_numeric']].groupby('first_parse').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_answers_context[(df_pred_answers_context['test_set_x'] == 'Amazon') & (df_pred_answers_context['model_name'] == 'xlnet-123(singlemodel)')][['f1','syllables_per_word']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4, figsize= (22,5))\n",
    "\n",
    "metric_list = ['f1','syllables_per_word', 'polysyllable_count','avg_word_length','avg_sentence_length_in_words','context_character_count',\n",
    "                                          'avg_sentence_length_in_characters','flesch-kincaid_grade_level','coleman-liau','gunning-fog','automated-readability']\n",
    "metric_list = ['f1', 'flesch-kincaid_grade_level','coleman-liau','gunning-fog','automated-readability']\n",
    "for i, model in enumerate(SET_NAMES):\n",
    "    corrMatrix = df_pred_answers_context[(df_pred_answers_context['test_set_x'] == model)][metric_list].corr()\n",
    "#     print(model)\n",
    "#    print(corrMatrix[0])\n",
    "#     print('\\n')\n",
    "    \n",
    "    p = sns.heatmap(corrMatrix, annot=True, ax = axes.flat[i], fmt=\".2f\")\n",
    "    axes.flat[i].set_title(model)\n",
    "\n",
    "    #p.set_xticklabels(p.get_xticklabels(), rotation = 0)\n",
    "    \n",
    "fig.tight_layout()\n",
    "#plt.savefig('test.jpg')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4, figsize= (22,5))\n",
    "\n",
    "metric_list = ['exact_match','syllables_per_word', 'polysyllable_count','avg_word_length','avg_sentence_length_in_words','context_character_count',\n",
    "                                          'avg_sentence_length_in_characters','flesch-kincaid_grade_level','coleman-liau','gunning-fog','automated-readability']\n",
    "metric_list = ['exact_match', 'flesch-kincaid_grade_level','coleman-liau','gunning-fog','automated-readability']\n",
    "for i, model in enumerate(SET_NAMES):\n",
    "    corrMatrix = df_pred_answers_context[(df_pred_answers_context['test_set_x'] == model)][metric_list].corr()\n",
    "#     print(model)\n",
    "#    print(corrMatrix[0])\n",
    "#     print('\\n')\n",
    "    \n",
    "    p = sns.heatmap(corrMatrix, annot=True, ax = axes.flat[i], fmt=\".2f\")\n",
    "    axes.flat[i].set_title(model)\n",
    "\n",
    "    #p.set_xticklabels(p.get_xticklabels(), rotation = 0)\n",
    "    \n",
    "fig.tight_layout()\n",
    "#plt.savefig('test.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "df_pred_answers_context[df_pred_answers_context['context'] == df_distinct_context.sort_values('flesch-kincaid_grade_level', ascending=False).iloc[2]['context']][['question_text', 'answer_text', 'predicted_answer', 'f1', 'exact_match']].drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
